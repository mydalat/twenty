# ü§ñ Enable AI Agent trong Twenty CRM

H∆∞·ªõng d·∫´n chi ti·∫øt ƒë·ªÉ enable v√† custom AI Agent s·ª≠ d·ª•ng getvoila API.

---

## üìã **T·ªïng Quan AI Agent**

Twenty CRM c√≥ t√≠ch h·ª£p AI Agent v·ªõi c√°c t√≠nh nƒÉng:

‚úÖ **Multi-Provider Support:**
- OpenAI (GPT-4o, GPT-4o-mini, GPT-4-turbo)
- Anthropic (Claude Opus 4, Sonnet 4, Haiku 3.5)
- xAI (Grok-3, Grok-4, Grok-mini)
- **OpenAI-Compatible** (Ollama, LM Studio, vLLM, **getvoila**, etc.)

‚úÖ **Agent Capabilities:**
- T·ª± ƒë·ªông t·∫°o tools t·ª´ database schema
- Multi-agent collaboration (handoffs)
- Workflow automation
- Web search & Twitter search (xAI models)
- Streaming responses

‚úÖ **Standard Agents:**
- Helper Agent - Documentation & help
- Data Navigator - Data exploration
- Data Manipulator - CRUD operations
- Workflow Builder - Workflow creation

---

## üöÄ **C√°ch 1: Enable AI Agent v·ªõi getvoila API** ‚≠ê (Khuy√™n d√πng cho b·∫°n)

### **Step 1: Chu·∫©n b·ªã getvoila API credentials**

Truy c·∫≠p: https://getvoila.ai (ho·∫∑c dashboard c·ªßa b·∫°n) v√† l·∫•y:
- API Key
- API Endpoint URL (VD: `https://api.getvoila.ai/v1` ho·∫∑c custom endpoint)
- Model names available (VD: `gpt-4o`, `gpt-4o-mini`, `claude-3.5-sonnet`)

### **Step 2: Configure Environment Variables**

Th√™m v√†o file `.env` c·ªßa Twenty:

```bash
# ============================================
# AI AGENT CONFIGURATION - getvoila
# ============================================

# Enable AI feature
# (ƒê√¢y l√† feature flag - ph·∫£i c√≥ ƒë·ªÉ enable AI)
# Kh√¥ng c·∫ßn set trong .env v√¨ t·ª± ƒë·ªông enable trong dev mode

# getvoila API Configuration (OpenAI-Compatible)
OPENAI_COMPATIBLE_BASE_URL=https://api.getvoila.ai/v1
OPENAI_COMPATIBLE_API_KEY=your_getvoila_api_key_here
OPENAI_COMPATIBLE_MODEL_NAMES=gpt-4o,gpt-4o-mini,gpt-4-turbo,claude-3.5-sonnet

# Default Models (ch·ªçn model m·∫∑c ƒë·ªãnh t·ª´ getvoila)
DEFAULT_AI_SPEED_MODEL_ID=gpt-4o-mini
DEFAULT_AI_PERFORMANCE_MODEL_ID=gpt-4o

# ============================================
# OPTIONAL: Fallback to original OpenAI/Anthropic
# (N·∫øu getvoila kh√¥ng available)
# ============================================
# OPENAI_API_KEY=sk-...
# ANTHROPIC_API_KEY=sk-ant-...
```

### **Step 3: Restart Server**

```bash
# Stop server n·∫øu ƒëang ch·∫°y (Ctrl+C)

# Clear cache (optional nh∆∞ng recommended)
rm -rf node_modules/.cache
rm -rf packages/twenty-server/dist

# Restart
yarn start
```

### **Step 4: Verify AI Agent ƒë√£ enable**

```bash
# Check logs khi server start
# Ph·∫£i th·∫•y d√≤ng t∆∞∆°ng t·ª±:
# [AI] Registered models: gpt-4o, gpt-4o-mini, gpt-4-turbo, claude-3.5-sonnet
# [AI] Default speed model: gpt-4o-mini
# [AI] Default performance model: gpt-4o
```

### **Step 5: Access AI Agent trong UI**

1. Login v√†o Twenty workspace
2. V√†o **Settings ‚Üí AI**
3. S·∫Ω th·∫•y danh s√°ch agents v√† models available
4. Click v√†o agent ƒë·ªÉ chat ho·∫∑c configure

---

## üöÄ **C√°ch 2: Enable AI Agent v·ªõi OpenAI tr·ª±c ti·∫øp**

N·∫øu mu·ªën d√πng OpenAI API tr·ª±c ti·∫øp thay v√¨ getvoila:

```bash
# .env
OPENAI_API_KEY=sk-proj-your-openai-api-key
DEFAULT_AI_SPEED_MODEL_ID=gpt-4o-mini
DEFAULT_AI_PERFORMANCE_MODEL_ID=gpt-4o
```

---

## üöÄ **C√°ch 3: D√πng nhi·ªÅu providers c√πng l√∫c**

C√≥ th·ªÉ config nhi·ªÅu providers v√† ch·ªçn model khi d√πng:

```bash
# .env
# OpenAI models
OPENAI_API_KEY=sk-proj-...

# Anthropic models
ANTHROPIC_API_KEY=sk-ant-...

# getvoila models (custom)
OPENAI_COMPATIBLE_BASE_URL=https://api.getvoila.ai/v1
OPENAI_COMPATIBLE_API_KEY=your_getvoila_key
OPENAI_COMPATIBLE_MODEL_NAMES=custom-model-1,custom-model-2

# Defaults
DEFAULT_AI_SPEED_MODEL_ID=gpt-4o-mini
DEFAULT_AI_PERFORMANCE_MODEL_ID=custom-model-1
```

---

## üéØ **getvoila API Requirements**

ƒê·ªÉ getvoila API ho·∫°t ƒë·ªông v·ªõi Twenty, endpoint ph·∫£i tu√¢n th·ªß **OpenAI API format**:

### **Required Endpoints:**

```
POST /v1/chat/completions
```

### **Request Format:**

```json
{
  "model": "gpt-4o",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Hello!"
    }
  ],
  "stream": true,
  "temperature": 0.7,
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "create_company",
        "description": "Create a new company",
        "parameters": {
          "type": "object",
          "properties": {
            "name": { "type": "string" }
          }
        }
      }
    }
  ]
}
```

### **Response Format (Streaming):**

```
data: {"id":"chatcmpl-123","object":"chat.completion.chunk","choices":[{"delta":{"content":"Hello"},"index":0}]}

data: {"id":"chatcmpl-123","object":"chat.completion.chunk","choices":[{"delta":{"content":" there"},"index":0}]}

data: [DONE]
```

### **Response Format (Non-streaming):**

```json
{
  "id": "chatcmpl-123",
  "object": "chat.completion",
  "model": "gpt-4o",
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop",
      "index": 0
    }
  ],
  "usage": {
    "prompt_tokens": 20,
    "completion_tokens": 10,
    "total_tokens": 30
  }
}
```

### **Tool Calling Support:**

getvoila API ph·∫£i support function calling (tools) theo OpenAI format:

```json
{
  "choices": [
    {
      "message": {
        "role": "assistant",
        "tool_calls": [
          {
            "id": "call_abc123",
            "type": "function",
            "function": {
              "name": "create_company",
              "arguments": "{\"name\": \"Acme Corp\"}"
            }
          }
        ]
      }
    }
  ]
}
```

---

## üîß **Troubleshooting**

### **1. AI Agent kh√¥ng xu·∫•t hi·ªán trong UI**

**Nguy√™n nh√¢n:** Feature flag ch∆∞a enable

**Gi·∫£i ph√°p:**
```bash
# Check database
psql -d twenty_db -c "SELECT * FROM core.\"featureFlag\" WHERE key = 'IS_AI_ENABLED';"

# Enable manually (n·∫øu c·∫ßn)
psql -d twenty_db -c "INSERT INTO core.\"featureFlag\" (key, value, \"workspaceId\") VALUES ('IS_AI_ENABLED', true, 'YOUR_WORKSPACE_ID');"
```

### **2. Error: "No AI models available"**

**Nguy√™n nh√¢n:** Environment variables ch∆∞a ƒë√∫ng

**Gi·∫£i ph√°p:**
```bash
# Check env variables
cd packages/twenty-server
node -e "require('dotenv').config(); console.log(process.env.OPENAI_COMPATIBLE_BASE_URL);"

# Verify trong logs khi server start
grep "Registered models" logs/server.log
```

### **3. Error: "Model not found"**

**Nguy√™n nh√¢n:** Model name kh√¥ng ƒë√∫ng ho·∫∑c kh√¥ng c√≥ trong OPENAI_COMPATIBLE_MODEL_NAMES

**Gi·∫£i ph√°p:**
```bash
# Check model names
echo $OPENAI_COMPATIBLE_MODEL_NAMES

# Update .env
OPENAI_COMPATIBLE_MODEL_NAMES=correct-model-name-1,correct-model-name-2

# Restart server
yarn start
```

### **4. getvoila API returns errors**

**Nguy√™n nh√¢n:** API endpoint kh√¥ng tu√¢n th·ªß OpenAI format

**Gi·∫£i ph√°p:**

Test API manually:
```bash
curl -X POST https://api.getvoila.ai/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [{"role": "user", "content": "Hello"}],
    "stream": false
  }'
```

Expected response ph·∫£i theo format OpenAI.

### **5. Agent kh√¥ng g·ªçi ƒë∆∞·ª£c tools/functions**

**Nguy√™n nh√¢n:** getvoila API kh√¥ng support function calling

**Gi·∫£i ph√°p:**
- Verify getvoila API c√≥ support `tools` parameter
- Check API documentation: https://docs.getvoila.ai (ho·∫∑c docs c·ªßa b·∫°n)
- N·∫øu kh√¥ng support, c√≥ th·ªÉ c·∫ßn wrapper middleware

---

## üìä **Verify Setup**

### **Test via GraphQL:**

```graphql
# 1. Check available models
query {
  availableAIModels {
    modelId
    label
    provider
  }
}

# 2. List agents
query {
  findManyAgents {
    edges {
      node {
        id
        name
        label
        modelId
      }
    }
  }
}

# 3. Test chat
mutation {
  createChatThread {
    id
  }
}
```

### **Test via REST API:**

```bash
# Get API key first: Settings ‚Üí APIs & Webhooks

# Create chat thread
curl -X POST http://localhost:3000/rest/agent-chat/stream \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "threadId": null,
    "messages": [
      {
        "role": "user",
        "content": "Hello, can you help me?"
      }
    ]
  }'
```

---

## üéÅ **Bonus: Custom AI Provider Integration**

N·∫øu getvoila API kh√¥ng ho√†n to√†n compatible v·ªõi OpenAI format, b·∫°n c√≥ th·ªÉ t·∫°o wrapper middleware:

### **Option 1: API Gateway/Proxy**

T·∫°o proxy server chuy·ªÉn ƒë·ªïi getvoila format ‚Üí OpenAI format:

```javascript
// proxy-server.js
const express = require('express');
const axios = require('axios');
const app = express();

app.post('/v1/chat/completions', async (req, res) => {
  // Convert OpenAI format ‚Üí getvoila format
  const getvoilaRequest = convertToGetvoilaFormat(req.body);

  // Call getvoila API
  const response = await axios.post(
    'https://api.getvoila.ai/your-endpoint',
    getvoilaRequest,
    { headers: { 'Authorization': `Bearer ${process.env.GETVOILA_API_KEY}` } }
  );

  // Convert getvoila response ‚Üí OpenAI format
  const openaiResponse = convertToOpenAIFormat(response.data);

  res.json(openaiResponse);
});

app.listen(8080, () => console.log('Proxy running on port 8080'));
```

Then config Twenty:
```bash
OPENAI_COMPATIBLE_BASE_URL=http://localhost:8080
```

### **Option 2: Modify Twenty Source Code**

T·∫°o custom provider trong Twenty:

File: `/packages/twenty-server/src/engine/core-modules/ai/services/ai-model-registry.service.ts`

```typescript
private registerGetvoilaModels(): void {
  const getvoilaApiKey = this.twentyConfigService.get('GETVOILA_API_KEY');

  if (!getvoilaApiKey) return;

  // Custom implementation cho getvoila
  const getvoilaProvider = createCustomProvider({
    baseURL: 'https://api.getvoila.ai',
    apiKey: getvoilaApiKey,
    // Custom transform logic
  });

  this.modelRegistry.set('getvoila-gpt4', {
    modelId: 'getvoila-gpt4',
    provider: ModelProvider.GETVOILA,
    model: getvoilaProvider('gpt-4'),
  });
}
```

---

## üìö **API Endpoints Reference**

### **GraphQL API:**

```
Endpoint: http://localhost:3000/metadata
```

**Queries:**
- `findManyAgents` - List all agents
- `findOneAgent(id)` - Get agent details
- `chatThreads` - List chat threads
- `chatMessages(threadId)` - Get messages

**Mutations:**
- `createOneAgent` - Create new agent
- `updateOneAgent` - Update agent config
- `deleteOneAgent` - Delete agent
- `createChatThread` - Start new chat
- `createAgentHandoff` - Setup agent collaboration

### **REST API:**

```
Endpoint: http://localhost:3000/rest/agent-chat/stream
Method: POST
```

**Request:**
```json
{
  "threadId": "uuid-or-null",
  "messages": [
    { "role": "user", "content": "Your message" }
  ],
  "recordIdsByObjectMetadataNameSingular": {
    "company": ["company-id-1", "company-id-2"]
  }
}
```

**Response:** Server-Sent Events (SSE) stream

---

## üéØ **Summary**

**Quick Setup cho getvoila:**

1. ‚úÖ Add to `.env`:
   ```bash
   OPENAI_COMPATIBLE_BASE_URL=https://api.getvoila.ai/v1
   OPENAI_COMPATIBLE_API_KEY=your_key
   OPENAI_COMPATIBLE_MODEL_NAMES=gpt-4o,gpt-4o-mini
   DEFAULT_AI_SPEED_MODEL_ID=gpt-4o-mini
   DEFAULT_AI_PERFORMANCE_MODEL_ID=gpt-4o
   ```

2. ‚úÖ Restart server: `yarn start`

3. ‚úÖ Access: Settings ‚Üí AI

4. ‚úÖ Test chat v·ªõi agents

**L∆∞u √Ω quan tr·ªçng:**
- getvoila API **PH·∫¢I** tu√¢n th·ªß OpenAI API format
- Ph·∫£i support **streaming** responses
- Ph·∫£i support **function calling** (tools) ƒë·ªÉ agents ho·∫°t ƒë·ªông ƒë√∫ng
- N·∫øu kh√¥ng compatible, c·∫ßn t·∫°o proxy/wrapper

---

## üîó **Links h·ªØu √≠ch:**

- Twenty AI Docs: (trong source code - kh√¥ng c√≥ public docs)
- OpenAI API Reference: https://platform.openai.com/docs/api-reference
- getvoila Docs: https://docs.getvoila.ai (n·∫øu c√≥)
- AI SDK (Vercel): https://sdk.vercel.ai/docs

---

**T·∫°o b·ªüi:** Claude Code
**Date:** 2025-11-13
**Version:** 1.0
